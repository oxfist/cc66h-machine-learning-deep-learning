{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lph11h3K_jM"
      },
      "source": [
        "# RNNs\n",
        "\n",
        "En este laboratorio aprenderás a usar distintos tipos de redes recurrentes y la\n",
        "aplicarás para clasificar un conjunto de reviews de películas de IMDB en\n",
        "\"positivo\" o \"negativo\". Partimos importando los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HLWy3bFpdDMV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsIaljDeLFBD"
      },
      "source": [
        "Cargamos los datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m8LCquLEs53W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "(40000,) (40000,)\n",
            "(10000,) (10000,)\n"
          ]
        }
      ],
      "source": [
        "max_palabras = 30000\n",
        "a_train = 15000\n",
        "\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.imdb.load_data(\n",
        "    num_words=max_palabras\n",
        ")\n",
        "\n",
        "# modificamos un poco los datasets para tener 40000 de train y 10000 de test\n",
        "X_train = np.concatenate((X_train, X_test[:a_train]), axis=0)\n",
        "Y_train = np.concatenate((Y_train, Y_test[:a_train]), axis=0)\n",
        "\n",
        "X_test = X_test[a_train:]\n",
        "Y_test = Y_test[a_train:]\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTIUF_laLJzU"
      },
      "source": [
        "Estas son funciones auxiliares para manejar textos y transformarlos en índices\n",
        "para poder trabajar más fácilmente con ellos. Si sabes un poco de python y\n",
        "tienes tiempo, dales una mirada. Son cosas standard que se deben hacer para\n",
        "procesar texto antes y después de pasárselos a una red neuronal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "a54_Dg6iiUnq"
      },
      "outputs": [],
      "source": [
        "palabra_a_id = keras.datasets.imdb.get_word_index()\n",
        "palabra_a_id = {k: (v + 3) for k, v in palabra_a_id.items()}\n",
        "id_a_palabra = {v: k for k, v in palabra_a_id.items()}\n",
        "id_a_palabra[0] = \"<PAD>\"\n",
        "id_a_palabra[1] = \"<INI>\"\n",
        "id_a_palabra[2] = \"<NN>\"\n",
        "\n",
        "\n",
        "def ids_a_texto(lista):\n",
        "    lista_palabras = [id_a_palabra[id] for id in lista]\n",
        "    texto = \" \".join(lista_palabras)\n",
        "    return texto\n",
        "\n",
        "\n",
        "def texto_a_ids(texto):\n",
        "    lista_palabras = texto.split()\n",
        "    lista = [1] + [palabra_a_id[w] if w in palabra_a_id else 2 for w in lista_palabras]\n",
        "    return lista\n",
        "\n",
        "\n",
        "def texto_a_red_input(texto, max_largo=80):\n",
        "    lista = texto_a_ids(texto)\n",
        "    X = np.array(lista).reshape(1, -1)\n",
        "    X = keras.preprocessing.sequence.pad_sequences(X, maxlen=max_largo)\n",
        "    return X\n",
        "\n",
        "\n",
        "def posneg(i):\n",
        "    if i < 0.5:\n",
        "        return \"negativo\"\n",
        "    else:\n",
        "        return \"positivo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mGfMNzpLffZ"
      },
      "source": [
        "Hacemos un preprocesamiento de los datos para que todos los textos tengan el\n",
        "mismo largo (80 en este caso).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVNZ-JAYkyNf"
      },
      "outputs": [],
      "source": [
        "max_largo = 80\n",
        "\n",
        "# mantenemos los originales\n",
        "X_train_original = X_train\n",
        "X_test_original = X_test\n",
        "\n",
        "# ahora los procesamos\n",
        "X_train = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_largo)\n",
        "X_test = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_largo)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1m1gAnJLVdH"
      },
      "source": [
        "Ejemplos de textos y sus etiquetas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSxbMnHotq5O"
      },
      "outputs": [],
      "source": [
        "N = 5\n",
        "for _ in range(N):\n",
        "    i = np.random.randint(len(X_test))\n",
        "    print(\"original:\", ids_a_texto(X_test_original[i]))\n",
        "    print(\"input red:\", ids_a_texto(X_test[i]))\n",
        "    print(\"etiqueta:\", posneg(Y_test[i]))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSt1ddq_L3VE"
      },
      "source": [
        "Importamos las capas recurrentes que usaremos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "v2WwYGkKvurP"
      },
      "outputs": [],
      "source": [
        "from keras.layers import SimpleRNN, GRU, LSTM, Embedding, Dense, Dropout, Bidirectional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbNd06haODqK"
      },
      "source": [
        "Creamos nuestra primera red recurrente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_Up9piZOv27A"
      },
      "outputs": [],
      "source": [
        "np.random.seed(30)\n",
        "tf.random.set_seed(30)\n",
        "\n",
        "emb_dim = 32\n",
        "\n",
        "rnn = keras.Sequential()\n",
        "rnn.add(Embedding(max_palabras, emb_dim, input_length=max_largo))\n",
        "rnn.add(SimpleRNN(32))\n",
        "rnn.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# rnn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbBe4z63OWHg"
      },
      "source": [
        "Compilamos y entrenamos nuestra red (solo por una época, si quieres puedes usar\n",
        "más pero las siguientes tardarán un tiempo considerablemente mayor). Usamos Adam\n",
        "como optimizador para mejorar las posibilidades de obtener una buena solución\n",
        "con pocas iteraciones (solo en una época).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DmuEcAsaw050"
      },
      "outputs": [],
      "source": [
        "rnn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "rnn.fit(X_train, Y_train, batch_size=32, epochs=1, validation_data=(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNnWxB0MT2W"
      },
      "source": [
        "Nuestro primer modelo llega a una certeza cercana al 83%.\n",
        "\n",
        "Mostramos las predicciones para algunos ejemplos. Note que ahora podemos pasarle\n",
        "como ejemplos textos propios para que pueda predecir. Si bien la certeza en el\n",
        "conjunto de prueba es bastante alta, las predicciones para ejemplos \"difíciles\"\n",
        "no son muy buenas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xUH8DQWgMTd3"
      },
      "outputs": [],
      "source": [
        "textos = [\n",
        "    \"this is a wonderful movie\",\n",
        "    \"this is a totally awful movie\",\n",
        "    \"this is an awful movie i really do not recommend it\",\n",
        "    \"this is the worst movie ever\",\n",
        "    \"i was expecting more way more\",\n",
        "    \"not what i expected but at the end i enjoyed it\",\n",
        "    \"i will see it again\",\n",
        "    \"i won't see it again\",\n",
        "    \"this is an excellent movie\",\n",
        "    \"if you are an idiot this is an excellent movie\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5e6coIrxGE3"
      },
      "outputs": [],
      "source": [
        "for texto in textos:\n",
        "    X_in = texto_a_red_input(texto, max_largo)\n",
        "    pred = rnn.predict(X_in)\n",
        "    print(texto)\n",
        "    print(posneg(pred.item()), pred.item())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7tpi-fGPsJe"
      },
      "source": [
        "# Ejercicio RNNs\n",
        "\n",
        "Trata de llegar a un 86% de certeza en el conjunto de prueba. Para esto prueba\n",
        "distintas opciones de arquitecturas (ojalá pruebes al menos 3 de creciente\n",
        "complejidad, sin olvidar la regularización). Comienza aumentando las neuronas\n",
        "del embedding a 64 y luego prueba algunas de las siguientes opciones:\n",
        "\n",
        "- RNN con más neuronas (en embedding o en la capa recurrente)\n",
        "- GRU o LSTM\n",
        "- GRU o LSTM bidireccional\n",
        "- dos (o mas?) capas de GRUs o LSTMs\n",
        "\n",
        "Si tienes más tiempo también puedes probar cambiando otros hiperparámetros\n",
        "(aunque sería bueno que para las primeras redes te fijes más que nada en la\n",
        "arquitectura).\n",
        "\n",
        "y similar para `GRU` y `LSTM`. Para poder poner una capa recurrente sobre otra\n",
        "debes usar el parámetro `return_sequences=True`. Con esto le dices a la red que\n",
        "esperas que retorne la capa escondida en cada iteración y no solo al final. Por\n",
        "ejemplo el siguiente trozo de código usa tres capas recurrentes una sobre otra\n",
        "\n",
        "```\n",
        "...\n",
        "red.add(SimpleRNN(32, return_sequences=True))\n",
        "red.add(SimpleRNN(16, return_sequences=True))\n",
        "red.add(SimpleRNN(8))\n",
        "red.add(Dense(1))\n",
        "...\n",
        "```\n",
        "\n",
        "la primera de recurrencia simple y 32 neuronas, la segunda es una capa de 16\n",
        "neuronas y la ultima una capa simple de 8 neuronas. Nota que la última capa\n",
        "recurrente no necesita el parámetro `return_sequences=True` pues solo se usará\n",
        "la capa escondida final para pasarla por la última capa densa.\n",
        "\n",
        "Para cada red que crees, calcula el acierto en el conjunto de prueba y muestra\n",
        "algunas predicciones de frases escritas por ti para ver cómo se comporta en\n",
        "distintos casos. De los casos complicados de arriba, las predicciones deberían\n",
        "empezar a mejorar (al menos respecto de la probabilidad que le asigna a ser\n",
        "positivo o negativo).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siX6xeP_6lg5"
      },
      "outputs": [],
      "source": [
        "# Acá comienza todo tu código"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH5CmiYQ2znt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Lab 6: Redes Recurrentes",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
